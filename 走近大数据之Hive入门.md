学习慕课网《走近大数据之Hive入门》教程的笔记。
简单介绍了hive的安装，使用和基础知识。

## 1-1 概述
Hive是基于Hadoop之上的__数据仓库(也是一种数据库)__。

## 1-2 数据仓库简介
数据仓库一般不更新，一直增大。

数据仓库的结构和建立过程：
``` sequence
participant 数据源
participant 数据存储及管理
participant 数据仓库引擎
participant 前端展示
Note over 数据源: 业务数据系统\n文档资料\n其他数据
数据源->数据存储及管理: 
Note over 数据存储及管理: 抽取E(xtract)\n转换T(ransform)\n装载L(oad)
数据存储及管理->数据仓库引擎: 
Note over 数据仓库引擎: 各种服务器
数据仓库引擎->前端展示: 
Note over 前端展示: 数据查询\n数据报表\n数据分析\n各类应用
```
OLTP：联机__事务__处理，例：银行转账。
OLAP：联机__分析__处理，例：商品推荐系统。
数据仓库的__数据模型__：1星型模型----(发展出)--> 2雪花模型。

星型模型
: 是个搭建数据的基础模型，数据仓库是面向主题的数据库。最后构建出的模型就类似一个星星。在中间的就是其中的主题，外围的信息和它相关。

雪花模型
: 基于星型模型发展来的，以星型的各个顶点为不同的主题，进而扩展。

## 1-3 什么是Hive
Hive是建立在Hadoop HDFS上的数据仓库基础架构。可以使用ETL处理数据。

## 2-1 Hive的体系结构之元数据
Hive的元数据：Hive将元数据存在数据库中，如：mysql，derby(默认数据库)等。Hive中的元数据包括__表的名字，表的列和分区及其属性，表的属性，表的数据所在的目录__等。

## 2-2 Hive的体系结构之HQL的执行过程
HQL是在Hive中执行的。
解释器，编译器，优化器完成HQL查询语句从__词法分析，语法分析，编译，优化以及查询计划(Plan)__的生成。生成的查询计划存储在HDFS中，并在随后MapReduce调用执行。
``` flow
st=>start: 
ed=>end: 
in=>inputoutput: HQL select
explain=>operation: 解释器：
进行词语分析，有语法错误就打印出来。
compile=>operation: 编译器：
生成HQL的执行计划。
optimizer=>operation: 优化器：
根据编译器生成的执行计划，进行调整生成最佳的执行计划。
done=>operation: 执行，得到结果。
st->in->explain->compile->optimizer->done->ed
```

## 2-3 Hive的体系结构
这里有个图片，详细的请看此视频。

## 3-1 Hive的安装模式
安装模式：

1. 嵌入模式：使用自带的derby数据库。仅用于演示。支持一个链接。
2. 本地模式：使用其他的数据库，数据库和hadoop在同一台物理机器上。如mysql数据库。
3. 远程模式：HIve和mysql运行在不用的物理机器上。支持多个链接。

## 3-2 Hive安装之嵌入模式

## 3-3 Hive安装之远程模式和本地模式

## 4-1 Hive的管理之CLI方式
Hive的启动方式：

+ CLI(命令行)方式
+ Web界面方式
+ 远程服务的启动方式

CLI：
: 直接输入hive可以进入命令行模式。

常用的CLI命令：

+ 清屏： C+L 或者 ！clear
+ 查看数据仓库中的表：show tables;
+ 查看数据仓库中的内置函数：show functions;
+ 注释： --
+ 查看表结构：desc 表名;
+ 查看HDFS上的文件：dfs -ls 目录;
+ 使用linux的命令：！命令;
+ 执行HQL语句：select ××× from ×××;
+ 执行SQL的脚本：source SQL文件; （和sql的文件执行命令一致）
+ hive -S 进入静默模式。不会输出mapreduce的调试信息。

## 4-2 Hive的管理之web界面方式
默认使用的端口是：9999。
启动方式：#hive --service hwi &
通过浏览器访问：http://< IP地址>:9999/hwi/

__这种方式只能进行查询操作。__

## 4-3 Hive的管理之远程服务
hive远程服务启动方式：
端口号：10000
启动方式：#hive --service hiveservice &

## 5-1 Hive的数据类型之基本数据类型
基本数据类型：

+ tinyint/smallint/int/bigint：整数类型
+ float/double：浮点数类型
+ boolean：布尔类型
+ string：字符串类型

可以在Hive wiki里查看详细的内容。

varchar(20)表示最长为20， char(20)表示字符串如果不是20，也按照20个字符存。

## 5-2 Hive的数据类型之复杂数据类型
复杂数据类型：

+ Array：数组类型。
+ Map：集合类型。只是key-> value 只能存一个值。
+ Struct：结构类型。可以通过“点语法”的方式来访问其中的元素。

## 5-3 Hive的数据类型之时间数据类型
时间类型：

+ Date：从Hive0.12.0开始支持。只有年月日。
+ Timestamp：从Hive0.8.0开始支持。和时区无关，是一个偏移量。可能就是秒数。

## 6-1 Hive的数据存储
基于HDFS。
没有专门的数据存储格式。可以使用txt或者cvs等等。默认使用tab作为分割符。
存储结构主要包括：__数据库、文件、表、视图__。
可以直接加载文本文件，如txt等。
创建表时，可以指定Hive数据的列分割符和行分割符。

__表分类__：

1. Table 内部表
2. Partition 分区表
3. External Table 外部表
4. Bucket Table 桶表

视图：类似于表。

## 6-2 内部表
__内部表__：

1. 和数据库中的table类似。
2. 每个table在Hive中都有一个对应的目录存储结构。
3. 所有的table的数据(不包括External table)都保存在这个目录下。
4. 删除表时，元数据和数据都会被删除。
创建表时，可以指定位置location，或者指定分割符如row format。

## 6-3 分区表
__分区表(Partition)__：

1. Partition对应于数据库的Partition列的密集索引。
2. 在Hive中，表中的一个Partition对应于表下的一个目录，所有的Partition数据都存储在对应的目录下。

在建立分区表时指定分区的条件，就是把数据库的数据按照什么原则来进行分类（放在不同的文件夹的文件里）。

## 6-4 外部表
__外部表(External Table)__：

1. 指向已经在HDFS存在的数据，可以创建Partition。
2. 和内部表在元数据组织上相同，实际数据的存储有较大的差异。
3. 外部表只是一个过程，创建表和加载数据同时完成。只是与外部数据建立一个连接，类似于快捷方式。

## 6-5 桶表
__桶表：__

1. 是对数据进行哈希取值，然后放到不同文件中存储。

可以提高查询速度。

## 6-6 视图
__视图：__

1. 是一中虚表，是一个逻辑概念，可以跨越多张表。
2. 视图是建立在已有表的基础上，它所依赖的表称为基表。
3. 视图可以简化查询操作。

## 7-1 总结
